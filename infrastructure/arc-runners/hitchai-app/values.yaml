# GitHub Actions Runner Scale Set - hitchai-app
#
# Lightweight Runner Strategy (12 concurrent runners):
# - Reduced per-runner limits (4Gi vs 12Gi) for higher parallelism
# - All volumes use tmpfs (medium: Memory) for maximum I/O performance
# - tmpfs is THIN-PROVISIONED: sizeLimit = upper bound, only actual writes consume RAM
# - ResourceQuota (50Gi total) prevents runaway usage across all pods
# - Per-pod actual usage: 1-2Gi typical, can burst to 4Gi
# - Trade-off: More concurrent jobs vs per-job memory

# Required: GitHub configuration
githubConfigUrl: "https://github.com/hitchai-app"
githubConfigSecret: "hitchai-app-github-app"

# CRITICAL: This name must match the runs-on label in workflows
# Defaults to Helm release name (hitchai-app-runners)
runnerScaleSetName: "hitchai-app-runners"

# Scaling
# Lightweight runner strategy: Reduced limits allow 12 concurrent runners
# ResourceQuota (50Gi limits.memory) caps total namespace usage to prevent node exhaustion
# CRITICAL: ResourceQuota enforces at limits level, not actual usage
# Current: 4Gi container limit × 12 runners = 48Gi (fits in 50Gi quota)
# Trade-off: Lower per-runner limits for higher parallelism
maxRunners: 12

# Runner pod template
# Documentation: https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller
# NOTE: The ARC chart auto-populates DinD containers when containerMode.type=dind
# (see chart values comments); we manage the sidecar explicitly here instead.
template:
  spec:
    # In DinD mode (Kubernetes v1.29+), the dind container runs as an init container with restartPolicy: Always
    # This makes it a native Kubernetes sidecar that starts before and runs alongside the runner container
    # Reference: https://github.blog/changelog/2025-06-13-actions-runner-controller-0-12-0-release/
    initContainers:
    # First init container: copies runner externals (binaries/tools) to shared volume
    # This is required for the DinD container to access runner tools
    - name: init-dind-externals
      image: ghcr.io/actions/actions-runner:latest
      command: ["cp", "-r", "/home/runner/externals/.", "/home/runner/tmpDir/"]
      resources:
        requests:
          cpu: "10m"
          memory: "64Mi"
        limits:
          cpu: "100m"
          memory: "128Mi"
      volumeMounts:
        - name: dind-externals
          mountPath: /home/runner/tmpDir

    # Second init container (sidecar): Docker daemon for workflow steps
    - name: dind
      image: docker:dind
      # Configure Docker daemon arguments
      # Documentation: https://docs.docker.com/reference/cli/dockerd/
      args:
        - dockerd
        # --host: Unix socket where Docker daemon listens
        # Required for runner container to communicate with Docker daemon via DOCKER_HOST env var
        - --host=unix:///var/run/docker.sock
        # --group: Sets GID for docker.sock to allow runner container access
        # The runner container runs with this GID to access the socket
        - --group=$(DOCKER_GROUP_GID)
        # --registry-mirror: Pull-through cache for Docker Hub images
        # First pull fetches from docker.io and caches locally, subsequent pulls served from cache
        # Mitigates Docker Hub rate limits (100 pulls/6h anonymous)
        # Documentation: https://docs.docker.com/docker-hub/mirror/
        - --registry-mirror=http://dockerhub-cache-docker-registry.registry-cache.svc.cluster.local:5000
      env:
        # GID 123 matches the docker group in the runner container
        # This allows the runner to access /var/run/docker.sock without being root
        - name: DOCKER_GROUP_GID
          value: "123"
      securityContext:
        # privileged: true required for DinD to function
        # Allows nested containerization (Docker daemon running in a container)
        privileged: true
      # restartPolicy: Always makes this init container a sidecar (runs throughout pod lifetime)
      # Without this, init container would exit after completion
      # Requires Kubernetes v1.29+ for native sidecar support
      restartPolicy: Always
      # Resource limits for Docker daemon (lightweight configuration)
      # Reduced limits for higher parallelism (12 runners vs 4)
      # Docker daemon: 200-500MB base + reduced layer caching
      # RAM-optimized: All Docker storage (layers, cache) lives in RAM via docker-lib volume
      resources:
        requests:
          cpu: "100m"
          memory: "128Mi"
        limits:
          cpu: "500m"
          memory: "2Gi"  # Reduced for lightweight builds
      # Startup probe ensures Docker daemon is ready before runner starts
      startupProbe:
        exec:
          command:
            - docker
            - info
        initialDelaySeconds: 0
        failureThreshold: 24
        periodSeconds: 5
      volumeMounts:
      - name: work
        mountPath: /home/runner/_work
      - name: dind-sock
        mountPath: /var/run
      - name: dind-externals
        mountPath: /home/runner/externals
      - name: docker-lib
        mountPath: /var/lib/docker  # Docker storage (layers, images, cache) in RAM

    containers:
    - name: runner
      image: ghcr.io/actions/actions-runner:latest
      command: ["/home/runner/run.sh"]
      # Lightweight runner strategy: Reduced limits for higher parallelism
      # RAM-optimized: All volumes use tmpfs (thin-provisioned, only actual usage consumes RAM)
      # Per-pod: 256Mi requests → 12 pods easily fit
      # Per-pod: 4Gi limits → 12 runners × 4Gi = 48Gi (within 50Gi quota)
      resources:
        requests:
          cpu: "100m"
          memory: "256Mi"
        limits:
          cpu: "1000m"
          memory: "4Gi"  # Reduced for lightweight builds, sufficient for most workflows
      env:
        # DOCKER_HOST tells the runner where to find the Docker daemon
        # Points to the Unix socket shared with the dind sidecar
        - name: DOCKER_HOST
          value: unix:///var/run/docker.sock
        # Maximum time runner waits for Docker daemon to be ready
        - name: RUNNER_WAIT_FOR_DOCKER_IN_SECONDS
          value: "120"
      volumeMounts:
      - name: work
        mountPath: /home/runner/_work
      - name: dind-sock
        mountPath: /var/run

    volumes:
    # RAM-optimized volumes: All use tmpfs (medium: Memory) for performance
    # tmpfs is THIN-PROVISIONED: sizeLimit is upper bound, only actual writes consume RAM
    # Volume sizeLimits must be ≤ container memory limit (tmpfs counts toward container usage)
    # Lightweight configuration: Reduced sizes for 12 concurrent runners
    # ResourceQuota (50Gi total) prevents runaway usage across all pods

    - name: work
      emptyDir:
        medium: Memory
        sizeLimit: 1Gi  # Workflow workspace (reduced for lightweight builds)

    - name: docker-lib
      emptyDir:
        medium: Memory
        sizeLimit: 3Gi  # Docker images, layers, build cache (reduced, registry cache helps)

    - name: dind-sock
      emptyDir:
        medium: Memory
        sizeLimit: 50Mi  # Unix socket for Docker communication

    - name: dind-externals
      emptyDir:
        medium: Memory
        sizeLimit: 200Mi  # Runner binaries and tools

# Explicitly link this scale set to the controller the chart failed to discover automatically.
controllerServiceAccount:
  namespace: arc-systems
  name: arc-gha-rs-controller
